{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd94cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "catalog_name = \"rainbow-data-production-iceberg\"\n",
    "spark = SparkSession.builder.appName(\"Spark-Iceberg\") \\\n",
    "    .config(\"spark.driver.userClassPathFirst\", \"false\") \\\n",
    "    .config(\"spark.executor.userClassPathFirst\", \"false\") \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}', 'org.apache.iceberg.spark.SparkCatalog') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.type', 'rest') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.uri', 'https://biglake.googleapis.com/iceberg/v1/restcatalog') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.warehouse', 'bq://projects/rainbow-data-production-483609') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.header.x-goog-user-project', 'rainbow-data-production-483609') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.rest.auth.type', 'org.apache.iceberg.gcp.auth.GoogleAuthManager') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.io-impl', 'org.apache.iceberg.gcp.gcs.GCSFileIO') \\\n",
    "    .config(f'spark.sql.catalog.{catalog_name}.rest-metrics-reporting-enabled', 'false') \\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.defaultCatalog', 'rainbow-data-production-iceberg') \\\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \",\".join([\n",
    "            \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.1\",\n",
    "            \"org.apache.iceberg:iceberg-gcp-bundle:1.10.1\",\n",
    "            \"com.google.auth:google-auth-library-oauth2-http:1.41.0\",\n",
    "            \"com.google.auth:google-auth-library-credentials:1.41.0\",\n",
    "            \"com.google.guava:guava:32.1.2-jre\",\n",
    "            \"com.google.cloud:google-cloud-storage:2.61.0\",\n",
    "            \"com.google.cloud:libraries-bom:26.73.0\",\n",
    "        ])\n",
    "    ) \\\n",
    "  .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             catalog|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "|       spark_catalog|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d2a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   current_catalog()|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_catalog();\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92d6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace ;\")\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace1 LOCATION 'gs://rainbow-data-production-iceberg/test_namespace1' WITH DBPROPERTIES ('gcp-region' = 'us-central1');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33981a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      namespace|\n",
      "+---------------+\n",
      "|           test|\n",
      "| test_namespace|\n",
      "|test_namespace1|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e56c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE test_namespace;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72201c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS sample_table (id BIGINT, data STRING) USING ICEBERG;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0358dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-----------+\n",
      "|     namespace|   tableName|isTemporary|\n",
      "+--------------+------------+-----------+\n",
      "|test_namespace|sample_table|      false|\n",
      "+--------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafc3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO sample_table VALUES\n",
    "  (1, 'first'), (2, 'second'), (3, 'third')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8badcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  1| first|\n",
      "|  2|second|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO sample_table VALUES\n",
    "  (4, 'fourth'), (5, 'fifth'), (6, 'sixth');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808bf8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  4|fourth|\n",
      "|  5| fifth|\n",
      "|  6| sixth|\n",
      "|  1| first|\n",
      "|  2|second|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sample_table;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4dcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
