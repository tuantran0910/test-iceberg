{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd94cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/14 00:07:33 WARN Utils: Your hostname, Trans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.102 instead (on interface en0)\n",
      "26/01/14 00:07:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/tranngoctuan0910/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/tranngoctuan0910/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-gcp-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0d91ac50-dd4b-455a-ac9f-679f671d87a4;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/tranngoctuan0910/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.10.1 in central\n",
      "\tfound org.apache.iceberg#iceberg-gcp-bundle;1.10.1 in central\n",
      ":: resolution report :: resolve 90ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-gcp-bundle;1.10.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.10.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0d91ac50-dd4b-455a-ac9f-679f671d87a4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "26/01/14 00:07:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "catalog_name = \"rainbow-data-production-iceberg\"\n",
    "project_id = \"rainbow-data-production-483609\"\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Spark-Iceberg\")\n",
    "    .config(\"spark.master\", \"local[*]\")\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.port\", \"7078\")\n",
    "    .config(\"spark.blockManager.port\", \"7079\")\n",
    "    .config(\"spark.driver.memory\", \"2G\")\n",
    "    .config(\"spark.executor.memory\", \"2G\")\n",
    "    .config(\"spark.driver.userClassPathFirst\", \"false\")\n",
    "    .config(\"spark.executor.userClassPathFirst\", \"false\")\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\"\n",
    "    )\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.type\", \"rest\")\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.uri\",\n",
    "        \"https://biglake.googleapis.com/iceberg/v1/restcatalog\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.warehouse\",\n",
    "        f\"bq://projects/{project_id}\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.header.x-goog-user-project\",\n",
    "        project_id,\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.rest.auth.type\",\n",
    "        \"org.apache.iceberg.gcp.auth.GoogleAuthManager\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.io-impl\",\n",
    "        \"org.apache.iceberg.gcp.gcs.GCSFileIO\",\n",
    "    )\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.rest-metrics-reporting-enabled\", \"false\")\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    )\n",
    "    .config(\"spark.sql.defaultCatalog\", catalog_name)\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \",\".join(\n",
    "            [\n",
    "                \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.1\",\n",
    "                \"org.apache.iceberg:iceberg-gcp-bundle:1.10.1\",\n",
    "                # \"com.google.auth:google-auth-library-oauth2-http:1.41.0\",\n",
    "                # \"com.google.auth:google-auth-library-credentials:1.41.0\",\n",
    "                # \"com.google.guava:guava:32.1.2-jre\",\n",
    "                # \"com.google.cloud:google-cloud-storage:2.61.0\",\n",
    "                # \"com.google.cloud:libraries-bom:26.73.0\",\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             catalog|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "|       spark_catalog|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d2a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   current_catalog()|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_catalog();\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dabb4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP NAMESPACE IF EXISTS test_namespace_bq_connection;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92d6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace_cv ;\")\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace_bq_connection LOCATION 'gs://rainbow-data-production-iceberg/test_namespace_bq_connection' WITH DBPROPERTIES ('gcp-region' = 'us');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33981a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|                test|\n",
      "|      test_namespace|\n",
      "|     test_namespace1|\n",
      "|   test_namespace_10|\n",
      "|test_namespace_bq...|\n",
      "|   test_namespace_cv|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05fd81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE test_namespace_bq_connection;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58718639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|           namespace|           tableName|isTemporary|\n",
      "+--------------------+--------------------+-----------+\n",
      "|test_namespace_bq...|my_table_with_bq_...|      false|\n",
      "+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd0d9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE my_table_with_bq_connection (\n",
    "        id BIGINT,\n",
    "        data STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    TBLPROPERTIES (\n",
    "        'bq_connection' = 'projects/rainbow-data-production-483609/locations/us/connections/iceberg_conn'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c0358dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|           namespace|           tableName|isTemporary|\n",
      "+--------------------+--------------------+-----------+\n",
      "|test_namespace_bq...|my_table_with_bq_...|      false|\n",
      "+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eafc3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO my_table_with_bq_connection VALUES\n",
    "  (1, 'first'), (2, 'second'), (3, 'third')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8badcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  1| first|\n",
      "|  4|fourth|\n",
      "|  5| fifth|\n",
      "|  2|second|\n",
      "|  6| sixth|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table_with_bq_connection\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1b7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO my_table_with_bq_connection VALUES\n",
    "  (4, 'fourth'), (5, 'fifth'), (6, 'sixth');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "808bf8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  4|fourth|\n",
      "|  5| fifth|\n",
      "|  6| sixth|\n",
      "|  1| first|\n",
      "|  2|second|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table_with_bq_connection;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503fc250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO my_table_with_bq_connection VALUES\n",
    "  (10, 'ten'), (11, 'eleven'), (12, 'twelve');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7349e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|        data|\n",
      "+---+------------+\n",
      "| 10|         ten|\n",
      "| 11|      eleven|\n",
      "| 12|      twelve|\n",
      "|  4|      fourth|\n",
      "|  1|       first|\n",
      "|  5|       fifth|\n",
      "|  2|      second|\n",
      "|  6|       sixth|\n",
      "|  3|       third|\n",
      "|  7|    new_data|\n",
      "|  8|   more_data|\n",
      "|  7|    new_data|\n",
      "|  8|   more_data|\n",
      "| 23|twenty three|\n",
      "| 24| twenty four|\n",
      "| 29| twenty nine|\n",
      "| 32|  thirty two|\n",
      "| 22|  twenty two|\n",
      "| 25| twenty five|\n",
      "| 28|twenty eight|\n",
      "+---+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table_with_bq_connection;\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246ef05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
