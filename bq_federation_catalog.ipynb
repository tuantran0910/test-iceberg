{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd94cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 632, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "            ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: '_control_lock'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 340, in dispatch_control\n",
      "    async with self._control_lock:\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 687, in __get__\n",
      "    return t.cast(G, self.get(obj, cls))  # the G should encode the Optional\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 649, in get\n",
      "    value = self._validate(obj, default)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 722, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 2311, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 831, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The '_control_lock' trait of an IPythonKernel instance expected a Lock, not the NoneType None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/tuan.tran1/Workspaces/Test/TestIceberg/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/tuan.tran1/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/tuan.tran1/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-gcp-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-275f5cdc-0db9-4e28-86de-12880964371d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.10.1 in central\n",
      "\tfound org.apache.iceberg#iceberg-gcp-bundle;1.10.1 in central\n",
      ":: resolution report :: resolve 83ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-gcp-bundle;1.10.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.10.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-275f5cdc-0db9-4e28-86de-12880964371d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/7ms)\n",
      "26/01/10 21:04:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "catalog_name = \"rainbow-data-production-iceberg\"\n",
    "project_id = \"rainbow-data-production-483609\"\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Spark-Iceberg\")\n",
    "    .config(\"spark.master\", \"local[*]\")\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.port\", \"7078\")\n",
    "    .config(\"spark.blockManager.port\", \"7079\")\n",
    "    .config(\"spark.driver.memory\", \"2G\")\n",
    "    .config(\"spark.executor.memory\", \"2G\")\n",
    "    .config(\"spark.driver.userClassPathFirst\", \"false\")\n",
    "    .config(\"spark.executor.userClassPathFirst\", \"false\")\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\"\n",
    "    )\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.type\", \"rest\")\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.uri\",\n",
    "        \"https://biglake.googleapis.com/iceberg/v1/restcatalog\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.warehouse\",\n",
    "        f\"bq://projects/{project_id}\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.header.x-goog-user-project\",\n",
    "        project_id,\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.rest.auth.type\",\n",
    "        \"org.apache.iceberg.gcp.auth.GoogleAuthManager\",\n",
    "    )\n",
    "    .config(\n",
    "        f\"spark.sql.catalog.{catalog_name}.io-impl\",\n",
    "        \"org.apache.iceberg.gcp.gcs.GCSFileIO\",\n",
    "    )\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.rest-metrics-reporting-enabled\", \"false\")\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    )\n",
    "    .config(\"spark.sql.defaultCatalog\", catalog_name)\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \",\".join(\n",
    "            [\n",
    "                \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.1\",\n",
    "                \"org.apache.iceberg:iceberg-gcp-bundle:1.10.1\",\n",
    "                # \"com.google.auth:google-auth-library-oauth2-http:1.41.0\",\n",
    "                # \"com.google.auth:google-auth-library-credentials:1.41.0\",\n",
    "                # \"com.google.guava:guava:32.1.2-jre\",\n",
    "                # \"com.google.cloud:google-cloud-storage:2.61.0\",\n",
    "                # \"com.google.cloud:libraries-bom:26.73.0\",\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             catalog|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "|       spark_catalog|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d2a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   current_catalog()|\n",
      "+--------------------+\n",
      "|rainbow-data-prod...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_catalog();\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dabb4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP NAMESPACE IF EXISTS test_namespace_bq_connection;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92d6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace_cv ;\")\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS test_namespace_bq_connection LOCATION 'gs://rainbow-data-production-iceberg/test_namespace_bq_connection' WITH DBPROPERTIES ('gcp-region' = 'us');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33981a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|                test|\n",
      "|      test_namespace|\n",
      "|     test_namespace1|\n",
      "|   test_namespace_10|\n",
      "|test_namespace_bq...|\n",
      "|   test_namespace_cv|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d05fd81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE test_namespace_bq_connection;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58718639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd0d9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE my_table_with_bq_connection (\n",
    "        id BIGINT,\n",
    "        data STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    TBLPROPERTIES (\n",
    "        'bq_connection' = 'projects/rainbow-data-production-483609/locations/us/connections/iceberg_conn'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c0358dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|           namespace|           tableName|isTemporary|\n",
      "+--------------------+--------------------+-----------+\n",
      "|test_namespace_bq...|my_table_with_bq_...|      false|\n",
      "+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eafc3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO my_table_with_bq_connection VALUES\n",
    "  (1, 'first'), (2, 'second'), (3, 'third')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8badcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  1| first|\n",
      "|  2|second|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table_with_bq_connection\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1b7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO my_table_with_bq_connection VALUES\n",
    "  (4, 'fourth'), (5, 'fifth'), (6, 'sixth');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "808bf8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  data|\n",
      "+---+------+\n",
      "|  4|fourth|\n",
      "|  5| fifth|\n",
      "|  6| sixth|\n",
      "|  1| first|\n",
      "|  2|second|\n",
      "|  3| third|\n",
      "+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_table_with_bq_connection;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fc250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
